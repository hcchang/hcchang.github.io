<!DOCTYPE html>
<html>
<body>

<h1 style="color:blue;">OpenCL 介紹</h1>

<p> OpenCL 是一個跨平台可以平行加速的˙一個套件，所以使用前最好有一些平行化的概念，<br>
    OpenCL 是Apple出來主導，希望開發者只要熟悉一種用法即可，所以可跨平台，包含iOs, MacOS, Android, Windows CUDA, Windows Intel, Linux <br>
	但是 nVidia的TK1, TX1, TX2, 官方似乎無支援，所以這部分可能還是要用CUDA才有辦法做平行化。<br>
    在使用類似GPU的套件時，我認為大致上可分成七大步驟<br><br>
	
&nbsp; &nbsp;	1. 和平台尋求需要的裝置  OpenCL: err = clGetPlatformIDs(0, 0, &num);   CUDA:  cudaStatus = cudaSetDevice(0);<br><br>
&nbsp; &nbsp;	2. 在Host(CPU)端，allocate CPU記憶體，準備把運算的內容複製到GPU端記憶體的部分<br>
&nbsp; &nbsp;	   unsigned char* srcImageBuffer = new unsigned char [DATA_SIZE];<br><br>
&nbsp; &nbsp;	3. 將Host的記憶體複製到GPU中的記憶體 <br>
&nbsp; &nbsp;		OpenCL: cl_mem cl_srcImage = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(cl_uchar)*DATA_SIZE, &srcImageBuffer[0], NULL);<br><br>
&nbsp; &nbsp;	4. 開始讀入文字檔 (OpenCL是用一個叫做 .cl的文字檔，可以稱Kernel，裡面主要寫著需要平行化的程式)，並給GPU用其指令集做編譯<br>
&nbsp; &nbsp;	    讀進來的文字都用char 儲存，<br>
&nbsp; &nbsp;		const char* source = &cldata[0];<br>
&nbsp; &nbsp;		將此source放到GPU內去做編譯:<br>
&nbsp; &nbsp;		cl_program program = clCreateProgramWithSource(context, 1, &source, 0, 0);<br><br>
&nbsp; &nbsp;	5. 開始計算，把要輸入的參數送到Kernel，並且設定需要平行化的維度和大小，<br>
&nbsp; &nbsp;        clSetKernelArg, clEnqueueNDRangeKernel,<br><br>
&nbsp; &nbsp;   6. 將算完的值從GPU的取出<br>
&nbsp; &nbsp;       clEnqueueReadBuffer<br><br>
&nbsp; &nbsp;   7. 釋放記憶體<br>
&nbsp; &nbsp;       clReleaseKernel, clReleaseMemObject, clReleaseProgram ....<br><br>


<hr>

步驟細節說明:<br><br>

&nbsp; &nbsp;  <h3>章節 1. 初始化GPU裝置</h3> <br>
<br>
&nbsp; &nbsp;&nbsp; &nbsp;  記得 include cl的頭檔 -> #include &#60CL\cl.h&#62<br>
&nbsp; &nbsp;&nbsp; &nbsp;  取得程式下有多少的平台 (platform)，通常為1，可能在分布式系統下可以有很多的平台: <br>
&nbsp; &nbsp;&nbsp; &nbsp;   err_num = clGetPlatformIDs(0, 0, &num_platforms);<br>
&nbsp; &nbsp;&nbsp; &nbsp;  當得到平台的數目後，可以將此平台的數目再次輸入，可以得到此platform的id，並用得到的platform id來創建 context	<br>
&nbsp; &nbsp;&nbsp; &nbsp;   err_num = clGetPlatformIDs(num_platforms, &platformsIds[0], &num_platforms);	<br>
&nbsp; &nbsp;&nbsp; &nbsp;  cl_context_properties properties[] = { CL_CONTEXT_PLATFORM, reinterpret_cast<cl_context_properties>(platformsIds[0]), 0 }; <br>
&nbsp; &nbsp;&nbsp; &nbsp;	cl_context context = clCreateContextFromType(properties, CL_DEVICE_TYPE_GPU, NULL, NULL, NULL);<br>
&nbsp; &nbsp;&nbsp; &nbsp;  context可以用來得到device的很多資訊，包含裝置的名稱，記憶體大小，等...<br><br>

&nbsp; &nbsp;範例程式: <br><br>

#include &#60iostream&#62<br>
#include &#60CL\cl.h&#62<br>
#include &#vector&#62<br>
<br>
int main(int argc, char** argv)<br>
{<br>
&nbsp; &nbsp;	cl_int err_num;<br>
&nbsp; &nbsp;	cl_uint num_platforms;<br>
&nbsp; &nbsp;	err_num = clGetPlatformIDs(0, 0, &num_platforms);<br>
&nbsp; &nbsp;	if (err_num != CL_SUCCESS)<br>
&nbsp; &nbsp;	{<br>
&nbsp; &nbsp;&nbsp; &nbsp;		std::cout << "can't get platforms" << std::endl;<br>
&nbsp; &nbsp;&nbsp; &nbsp;		return 0;<br>
&nbsp; &nbsp;	}<br>
<br>
&nbsp; &nbsp;	std::cout << "platform numbers: " << num_platforms << std::endl;<br>
&nbsp; &nbsp;	std::vector<cl_platform_id> platformsIds(num_platforms);<br>
&nbsp; &nbsp;	err_num = clGetPlatformIDs(num_platforms, &platformsIds[0], &num_platforms);<br>
&nbsp; &nbsp;	if (err_num != CL_SUCCESS)<br>
&nbsp; &nbsp;	{<br>
&nbsp; &nbsp;&nbsp; &nbsp;		std::cout << "can't get platforms IDs" << std::endl;<br>
&nbsp; &nbsp;&nbsp; &nbsp;		return 0;<br>
&nbsp; &nbsp;	}<br>
<br>
&nbsp; &nbsp;	std::cout << "how many platform ids: " << platformsIds.size() << std::endl;<br>
&nbsp; &nbsp;	cl_context_properties properties[] = { CL_CONTEXT_PLATFORM, reinterpret_cast<cl_context_properties>(platformsIds[0]), 0 };<br>
&nbsp; &nbsp;	cl_context context = clCreateContextFromType(properties, CL_DEVICE_TYPE_GPU, NULL, NULL, NULL);<br>
&nbsp; &nbsp;	if (context == 0)<br>
&nbsp; &nbsp;   {<br>
&nbsp; &nbsp;&nbsp; &nbsp;		std::cout << "can't create OpenCL context" << std::endl;<br>
&nbsp; &nbsp;&nbsp; &nbsp;		return 0;<br>
&nbsp; &nbsp;	}<br>
<br>
&nbsp; &nbsp;	size_t param_value_size;<br>
&nbsp; &nbsp;	clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &param_value_size);<br>
&nbsp; &nbsp;	std::vector<cl_device_id> devices(param_value_size / sizeof(cl_device_id));<br>
&nbsp; &nbsp;	clGetContextInfo(context, CL_CONTEXT_DEVICES, param_value_size, &devices[0], 0);  ////get context<br>
<br>
&nbsp; &nbsp;	char device_string[1024];<br>
&nbsp; &nbsp;	char dname[500];<br>
&nbsp; &nbsp;	size_t workitem_size[3];<br>
&nbsp; &nbsp;	cl_device_id device = devices[0];<br>
<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_NAME, sizeof(device_string), &device_string, NULL);<br>
&nbsp; &nbsp;	std::cout << "DEVICE: " << device_string << std::endl;<br>
<br>
&nbsp; &nbsp;	// CL_DEVICE_INFO<br>
&nbsp; &nbsp;	cl_device_type type;<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_TYPE, sizeof(type), &type, NULL);<br>
&nbsp; &nbsp;	if (type & CL_DEVICE_TYPE_CPU)<br>
&nbsp; &nbsp;		std::cout << "CL_DEVICE_TYPE: " << "CL_DEVICE_TYPE_CPU" << std::endl;<br>
&nbsp; &nbsp;	if (type & CL_DEVICE_TYPE_GPU)<br>
&nbsp; &nbsp;&nbsp; &nbsp;		std::cout << "CL_DEVICE_TYPE: " << "CL_DEVICE_TYPE_GPU" << std::endl;<br>
&nbsp; &nbsp;	if (type & CL_DEVICE_TYPE_ACCELERATOR)<br>
&nbsp; &nbsp;&nbsp; &nbsp;		std::cout << "CL_DEVICE_TYPE: " << "CL_DEVICE_TYPE_ACCELERATOR" << std::endl;<br>
&nbsp; &nbsp;	if (type & CL_DEVICE_TYPE_DEFAULT)<br>
&nbsp; &nbsp;&nbsp; &nbsp;		std::cout << "CL_DEVICE_TYPE: " << "CL_DEVICE_TYPE_DEFAULT" << std::endl;<br>
<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DRIVER_VERSION, 500, dname, NULL);<br>
&nbsp; &nbsp;	std::cout << "Driver version = : " << dname << std::endl;<br>
<br>
&nbsp; &nbsp;	cl_ulong long_entries;<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_GLOBAL_MEM_SIZE, sizeof(cl_ulong), &long_entries, NULL);<br>
&nbsp; &nbsp;	std::cout << "Global Memory (MB): " << long_entries / 1024 / 1024 << std::endl;<br>
<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_GLOBAL_MEM_CACHE_SIZE, sizeof(cl_ulong), &long_entries, NULL);<br>
&nbsp; &nbsp;	std::cout << "Global Memory Cache (B): " << long_entries << std::endl;<br>
<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_LOCAL_MEM_SIZE, sizeof(cl_ulong), &long_entries, NULL);<br>
&nbsp; &nbsp;	std::cout << "Local Memory (B): " << long_entries << std::endl;<br>
<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_MAX_CLOCK_FREQUENCY, sizeof(cl_ulong), &long_entries, NULL);<br>
&nbsp; &nbsp;	std::cout << "CL_DEVICE_MAX_CLOCK_FREQUENCY: " << long_entries << " GHz" << std::endl;<br>
<br>
&nbsp; &nbsp;	cl_uint compute_units;<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(compute_units), &compute_units, NULL);<br>
&nbsp; &nbsp;	std::cout << "CL_DEVICE_MAX_COMPUTE_UNITS: " << compute_units << std::endl;<br>
<br>
&nbsp; &nbsp;	clGetDeviceInfo(device, CL_DEVICE_MAX_WORK_ITEM_SIZES, sizeof(workitem_size), &workitem_size, NULL);<br>
&nbsp; &nbsp;	std::cout << "CL_DEVICE_MAX_WORK_ITEM_SIZES: " << workitem_size[0] << "x" << workitem_size[1] << "x" << workitem_size[2] << std::endl;<br>
<br>
&nbsp; &nbsp;	return 0;<br>
}<br>
	    
<hr>	

&nbsp; &nbsp;  <h3>章節 2. 將計算的記憶體從Host複製到GPU並實現簡易的MedianFilter範例</h3> <br>
<br>


</body>
</html>
